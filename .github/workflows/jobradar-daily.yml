name: JobRadar Daily Scraper

on:
  schedule:
    # Runs at 8:00 AM Melbourne time (AEDT = UTC+11)
    # 8 AM AEDT = 9 PM UTC (21:00)
    # GitHub Actions can have 5-15 min delay, so this should run ~8:00-8:15 AM
    - cron: '0 21 * * *'
  
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y python3-pip
      
      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install supabase python-dotenv requests beautifulsoup4 tenacity playwright
          playwright install chromium
          playwright install-deps
      
      - name: Run JobRadar ingestion
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          SMTP_HOST: ${{ secrets.SMTP_HOST }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
          SMTP_USER: ${{ secrets.SMTP_USER }}
          SMTP_PASS: ${{ secrets.SMTP_PASS }}
          ALERT_TO: ${{ secrets.ALERT_TO }}
        run: |
          python -m app.ingest
      
      - name: Upload logs (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: error-logs
          path: |
            *.log
            **/*.log
